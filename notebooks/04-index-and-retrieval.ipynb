{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pyprojroot import here\n",
    "\n",
    "from poorman_graphrag.index import GraphRAGIndex\n",
    "\n",
    "index = GraphRAGIndex.load(here() / \"data\" / \"deduplicated_index_with_communities.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import llamabot as lmb\n",
    "import networkx as nx\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from poorman_graphrag.network import build_network\n",
    "\n",
    "\n",
    "class EnhancedQuery(BaseModel):\n",
    "    queries: list[str] = Field(\n",
    "        description=\"A list of strings for which to use vector (semantic) search.\"\n",
    "    )\n",
    "    keywords: list[str] = Field(\n",
    "        description=\"A list of strings for which to use keyword search.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def query_enhancer(query: str, index: GraphRAGIndex, top_k: int = 10) -> EnhancedQuery:\n",
    "    enhancerbot = lmb.StructuredBot(\n",
    "        system_prompt=(\n",
    "            \"You are a helpful assistant that takes in a user's query, \"\n",
    "            \"which may be generic, incomplete, vague, \"\n",
    "            \"or otherwise not usefully formulated, \"\n",
    "            \"and returns a list of queries \"\n",
    "            \"that are more specific, complete, and usefully formulated.\"\n",
    "        ),\n",
    "        pydantic_model=EnhancedQuery,\n",
    "        model_name=\"gpt-4o\",\n",
    "    )\n",
    "\n",
    "    G = build_network(index)\n",
    "\n",
    "    # Compute the betweenness centrality and degree centrality of the nodes in the graph\n",
    "    betweenness_centrality = nx.betweenness_centrality(G)\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "\n",
    "    # Get the top 10 nodes by betweenness centrality and degree centrality\n",
    "    top_betweenness = sorted(\n",
    "        betweenness_centrality.items(), key=lambda x: x[1], reverse=True\n",
    "    )[:top_k]\n",
    "    top_degree = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[\n",
    "        :top_k\n",
    "    ]\n",
    "\n",
    "    # Now, collect their metadata dictionaries into a long JSON string\n",
    "    # and pass it to the LLM.\n",
    "    metadata = [G.nodes[node[0]] for node in top_betweenness + top_degree]\n",
    "    metadata_str = json.dumps(metadata)\n",
    "\n",
    "    return enhancerbot(\n",
    "        lmb.user(\n",
    "            f\"This is the original query: {query}\",\n",
    "            \"These are the top 10 nodes by \",\n",
    "            \"betweenness centrality and degree centrality, \"\n",
    "            f\"and their metadata: {metadata_str}\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "enhanced_query = query_enhancer(\"Tell me about the study.\", index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_docstore = lmb.BM25DocStore()\n",
    "keyword_docstore.extend(index.chunk_index.values())\n",
    "keyword_docstore.extend(index.doc_index.values())\n",
    "keyword_docstore.extend([entity.summary for entity in index.entity_index.values()])\n",
    "\n",
    "results = keyword_docstore.retrieve(\"hypothesis\")\n",
    "[len(result) for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_docstore = lmb.LanceDBDocStore(table_name=\"dummy-1038vkch\")\n",
    "vector_docstore.extend(index.chunk_index.values())\n",
    "vector_docstore.extend(index.doc_index.values())\n",
    "vector_docstore.extend([entity.summary for entity in index.entity_index.values()])\n",
    "\n",
    "results = vector_docstore.retrieve(\"hypothesis\")\n",
    "[len(result) for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
